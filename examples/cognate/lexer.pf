import

"strings"
"unicode"

const

WHITESPACE = set(' ', '\t')
PUNCTUATION = set('(', ')', ';')

newtype 

Token = struct(lit string, line, ch int)

def 

tokenize(code string) -> list :
    from tokens = [] for i::s = range lines :
        tokens + slurpLine s, i + 1
given :
    lines = strings.split code, "\n"

slurpLine(code string, lineNumber int) -> list : 
    first from tokens, pos = [], 0 for :
        nextChar == len word :
            break
        unicode.isLower word[0] :
            tokens, nextChar
        else :
            tokens + [Token(word, lineNumber, firstChar)], nextChar
         .. 
    given :
        unprocessedCode = code[pos::len code]
        firstChar = pos + skipWhitespace unprocessedCode
        word = slurpNext code[firstChar::len code]
        nextChar = firstChar + len word

slurpNext(code string) -> string : 
    code[0] == '"' : 
        slurpTo(code, set("\""))
    code[0] in PUNCTUATION :
        string(code[0])
    else :
        slurpTo(code, WHITESPACE + PUNCTUATION)

skipWhitespace(code string) -> int :
    from count = 0 for i = 0; i < len(code) and code[i] in WHITESPACE; i + 1 :
        count + 1

slurpTo (code string, terminators set) : 
    from result = "" for i = 0; not (i == len code or code[i] in terminators); i + 1 :
        result + code[i] 

